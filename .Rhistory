library(mclust)
BIC <- mclustBIC(photo.pairs_sub)
plot(AIC)
photo.pairs = read.csv("Photo_pairs.csv")
names(photo.pairs)
photo.pairs_sub = subset(photo.pairs, select=c("redshift"))
library(mclust)
AIC <- mclustAIC(photo.pairs_sub)
photo.pairs = read.csv("Photo_pairs.csv")
names(photo.pairs)
photo.pairs_sub = subset(photo.pairs, select=c("redshift"))
library(mclust)
BIC <- mclustBIC(photo.pairs_sub)
plot(BIC)
mod1 <- Mclust(photo.pairs_sub, x = BIC)
EM <- mclustEM(photo.pairs_sub)
photo.pairs = read.csv("Photo_pairs.csv")
names(photo.pairs)
photo.pairs_sub = subset(photo.pairs, select=c("redshift"))
library(mclust)
BIC <- mclustBIC(photo.pairs_sub)
plot(BIC)
mod1 <- Mclust(photo.pairs_sub, x = BIC)
mod1
typeof(mod1$classification)
class(mod1$classification)
str(mod1$classification)
# read the data
dat_2000 <- read.csv("Photo_pairs.csv", header = TRUE)
dat_2000.features <- data.frame(dat_2000$redshift, dat_2000[,c("g","r","i","z")]/dat_2000$u)
# Normalize data matrix to have the same variance
dat_2000.features <- scale(dat_2000.features, scale=TRUE)
# I try different radius of the neighborhood and found out 0.05
# to be a good parameter as almost all groups have
rslt_2000 <- hdbscan(dat_2000.features, minPts=2, gen_simplified_tree=TRUE)
rslt_2000
# read the data
dat_2000 <- read.csv("Photo_pairs.csv", header = TRUE)
dat_2000.features <- data.frame(dat_2000$redshift, dat_2000[,c("g","r","i","z")]/dat_2000$u)
# Normalize data matrix to have the same variance
dat_2000.features <- scale(dat_2000.features, scale=TRUE)
# I try different radius of the neighborhood and found out 0.05
# to be a good parameter as almost all groups have
rslt_2000 <- dbscan(dat_2000.features, minPts=2, gen_simplified_tree=TRUE)
# read the data
dat_2000 <- read.csv("Photo_pairs.csv", header = TRUE)
dat_2000.features <- data.frame(dat_2000$redshift, dat_2000[,c("g","r","i","z")]/dat_2000$u)
# Normalize data matrix to have the same variance
dat_2000.features <- scale(dat_2000.features, scale=TRUE)
# I try different radius of the neighborhood and found out 0.05
# to be a good parameter as almost all groups have
rslt_2000 <- dbscan(dat_2000.features, minPts=2, eps = .05)
rslt_2000
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
# Read in the large scale data
dat_large <- read.csv("Photo_pairs_100000.csv", header = TRUE, skip=1)
View(dat_large)
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
# Load the csv file into data and
dat_small <- read.csv("Photo_pairs.csv", header = TRUE, skip = 1)
dat_small <- dat_small[-which(dat_small$redshift>1.2),]
library(dbscan)
view(dat_small)
View(dat_small)
pairs(dat_small[,c("g,"r","i","z")]/dat_small$u)
pairs(dat_small[,c("g,"r","i","z")]/dat_small$u)
pairs(dat_small[,c(g,"r","i","z")])
pairs(dat_small[,c("g","r","i","z")])
pairs(dat_small[,c("g,"r","i","z")]/dat_small$c_u)
pairs(dat_small[,c("c_g","c_r","c_i","c_z")]/dat_small$c_u)
pairs(scale(dat_small[,c("c_g","c_r","c_i","c_z")]/dat_small$c_u))
pairs(scale(dat_small[,c("g","r","i","z")]/dat_small$u))
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
# Load the csv file into data and
dat_small <- read.csv("Photo_pairs.csv", header = TRUE, skip = 1)
dat_small <- dat_small[-which(dat_small$redshift>1.2),]
library(dbscan)
# Load the csv file into data and
dat_small <- read.csv("Photo_pairs.csv", header = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(dbscan)
View(dat_small)
dat_small$objid
dat_small$objid[1]
dat_small$objid[1] == dat_small$objid
dat_small$objid[1] == dat_small$objid[2]
dat_small$objid[1] == dat_small$objid[1]
# Read in small data
dat_small <- read.csv("Photo_pairs.csv", header = TRUE, skip = 1)
# get rid of anomalies
anom_idx <- dat_small$objid[dat_small$c_u < -10]
min(dat_small$u)
min(dat_small$c_u)
knitr::opts_chunk$set(echo = TRUE)
library(dbscan)
# Read in small scaled data
dat_small <- read.csv("Photo_pairs.csv", header = TRUE, skip = 1)
range(dat_small$redshift)
View(dat_small)
?seq
seq(dat_small)
seq(dat_small$redshift)
seq(dat_small$redshift, length.out=10)
# Use rolling window to obtain subset of galaxies with similar redshift
# Use window centers evenly spread out through the range of
redshift_centers <- seq(from = min(dat_small$redshift),
to = max(dat_small$redshift),
length.out=11)
# Read in small scaled data
dat_small <- read.csv("Photo_pairs.csv", header = TRUE, skip = 1)
redshift <- dat_small$redshift
# Use rolling window to obtain subset of galaxies with similar redshift
# Use window centers evenly spread out through the range of
redshift_centers <- seq(from = min(dat_small$redshift),
to = max(dat_small$redshift),
length.out=11)
# Use normalized composite magnitude
cMag_bands <- c("c_u", "c_g", "c_r", "c_i", "c_z")
cMag_norm <- dat_small[, cMag_bands]/dat_small$c_u
# Use a bandwidth of 0.5 to select galaxy with similar red shifts
# at each window center
h <- 0.5
for(c in redshift_centers) {
dat_sub <- dat_small[]
<- dat_
# Use rolling window to obtain subset of galaxies with similar redshift
# Use window centers evenly spread out through the range of
redshift_centers <- seq(from = min(dat_small$redshift),
to = max(dat_small$redshift),
length.out=11)
# Use normalized composite magnitude
cMag_bands <- c("c_u", "c_g", "c_r", "c_i", "c_z")
cMag_norm <- dat_small[, cMag_bands]/dat_small$c_u
# Use a bandwidth of 0.5 to select galaxy with similar red shifts
# at each window center
h <- 0.5
for(c in redshift_centers) {
dat_sub <- dat_small[abs(redshift-c) <= h/2,]
}
View(dat_sub)
?dbscna
?dbscan
?DBSCAN
dat_large$c_u< -10
which(dat_large$c_u< -10)
dat_small$c_u< -10
which(dat_small$c_u< -10)
knitr::opts_chunk$set(echo = TRUE)
library(dbscan)
# Read in small scaled data
dat_small <- read.csv("Photo_pairs.csv", header = TRUE, skip = 1)
redshift <- dat_small$redshift
redshift <- dat_small$redshift
which(dat_small$c_u< -10)
knitr::opts_chunk$set(echo = TRUE)
library(dbscan)
# Read in small scaled data
dat_small <- read.csv("../Data/Photo_pairs.csv", header = TRUE, skip = 1)
redshift <- dat_small$redshift
pairsCatalog <- function(pairs, vec){
#' pairsCatalog
#'
#' A function that takes in a list pairs and a vec consisited of galaxy IDs; returns
#' a list which has cataloged vec
#'
#' pairs should be a list where each cell contains galaxy IDs. Each cell represents
#' a sosie pair (or triplets).
#'
#' vec is a vector which contains ID that is supposed to be catalogued in the pairs
# Instantiate the updated vector
pairs.updated <- list()
cross_listed.flg <- TRUE
for(pair in pairs){
# If the pair doesn't contain the objects, then just
# append the vector to updated lists
if(sum(pair %in% vec) == 0){
pairs.updated <- append(pairs.updated, list(pair))
}
else{
# If the pair intersects with vec (contain same id), then group
# the pair and vec into a new group and append to the updated
# pairs
cross_listed.flg <- FALSE
pairs.updated <- append(pairs.updated,
list(unique(c(pair, vec))))
}
}
if(cross_listed.flg) {
pairs.updated <- append(pairs.updated, list(vec))
}
return(pairs.updated)
}
# Use rolling window to obtain subset of galaxies with similar redshift
# Use window centers evenly spread out through the range of
redshift_centers <- seq(from = min(dat_small$redshift),
to = max(dat_small$redshift),
length.out=11)
# Use normalized composite magnitude
cMag_bands <- c("c_g", "c_r", "c_i", "c_z")
cMag_norm <- dat_small[, cMag_bands]/dat_small$c_u
#cMag_scaled <- scale(cMag_norm, center=FALSE)
# Use a bandwidth of 0.5 to select galaxy with similar red shifts
# at each window center
h <- 0.5
# Establish a new list called sosies, which stores our
# sosie paris (or triplets)
sosies <- list()
for(c in redshift_centers) {
# Obtain the filtered series
indx <- (1:nrow(dat_small))[abs(redshift-c) <= h/2]
dat_sub <- dat_small[indx,]
# Continue if the subset has more than 1 observation
if (length(indx) > 1) {
# Use DBSCAN to find pairs based on Normalized Magnitude
rslt <- dbscan(cMag_norm[indx, ], minPts = 2, eps = .05)$cluster
# if there is only noise, then skip; otherwise, catalog the pairs with
# their ID
if(length(unique(rslt)) != 1) {
# Obtain total number of groups in clustering result
group.level <- unique(rslt)
for(group in group.level[-1]){
# Obtain id for the galaxies that are classified
# as pairs
groupId <- dat_sub$objid[rslt == group]
sosies <- pairsCatalog(sosies, groupId)
}
}
}
}
# Check the clustering result
rslt1 <- dat_small[dat_small$objid %in% sosies[[1]], ]
View(rslt1)
matplot(rslt1[,c("c_u","c_g","c_r","c_i","c_z")],type='l')
# Check the clustering result
rslt1 <- dat_small[dat_small$objid %in% sosies[[1]], ]
matplot(t(rslt1[,c("c_u","c_g","c_r","c_i","c_z")]),type='l')
pairsCatalog <- function(pairs, vec){
#' pairsCatalog
#'
#' A function that takes in a list pairs and a vec consisited of galaxy IDs; returns
#' a list which has cataloged vec
#'
#' pairs should be a list where each cell contains galaxy IDs. Each cell represents
#' a sosie pair (or triplets).
#'
#' vec is a vector which contains ID that is supposed to be catalogued in the pairs
# Instantiate the updated vector
pairs.updated <- list()
cross_listed.flg <- TRUE
for(pair in pairs){
# If the pair doesn't contain the objects, then just
# append the vector to updated lists
if(sum(pair %in% vec) == 0){
pairs.updated <- append(pairs.updated, list(pair))
}
else{
# If the pair intersects with vec (contain same id), then group
# the pair and vec into a new group and append to the updated
# pairs
cross_listed.flg <- FALSE
pairs.updated <- append(pairs.updated,
list(unique(c(pair, vec))))
}
}
if(cross_listed.flg) {
pairs.updated <- append(pairs.updated, list(vec))
}
return(pairs.updated)
}
# Use rolling window to obtain subset of galaxies with similar redshift
# Use window centers evenly spread out through the range of
redshift_centers <- seq(from = min(dat_small$redshift),
to = max(dat_small$redshift),
length.out=11)
# Use normalized composite magnitude
cMag_bands <- c("c_g", "c_r", "c_i", "c_z")
cMag_norm <- dat_small[, cMag_bands]/dat_small$c_u
#cMag_scaled <- scale(cMag_norm, center=FALSE)
# Use a bandwidth of 0.5 to select galaxy with similar red shifts
# at each window center
h <- 0.5
# Establish a new list called sosies, which stores our
# sosie paris (or triplets)
sosies <- list()
for(c in redshift_centers) {
# Obtain the filtered series
indx <- (1:nrow(dat_small))[abs(redshift-c) <= h/2]
dat_sub <- dat_small[indx,]
# Continue if the subset has more than 1 observation
if (length(indx) > 1) {
# Use DBSCAN to find pairs based on Normalized Magnitude
rslt <- dbscan(cMag_norm[indx, ], minPts = 2, eps = .02)$cluster
# if there is only noise, then skip; otherwise, catalog the pairs with
# their ID
if(length(unique(rslt)) != 1) {
# Obtain total number of groups in clustering result
group.level <- unique(rslt)
for(group in group.level[-1]){
# Obtain id for the galaxies that are classified
# as pairs
groupId <- dat_sub$objid[rslt == group]
sosies <- pairsCatalog(sosies, groupId)
}
}
}
}
# Check the clustering result
rslt1 <- dat_small[dat_small$objid %in% sosies[[1]], ]
matplot(t(rslt1[,c("c_u","c_g","c_r","c_i","c_z")]),type='l')
# Check the clustering result
rslt1 <- dat_small[dat_small$objid %in% sosies[[1]], ]
matplot(t(rslt2[,c("c_u","c_g","c_r","c_i","c_z")]),type='l')
# Use rolling window to obtain subset of galaxies with similar redshift
# Use window centers evenly spread out through the range of
redshift_centers <- seq(from = min(dat_small$redshift),
to = max(dat_small$redshift),
length.out=11)
# Use normalized composite magnitude
cMag_bands <- c("c_g", "c_r", "c_i", "c_z")
cMag_norm <- dat_small[, cMag_bands]/dat_small$c_u
#cMag_scaled <- scale(cMag_norm, center=FALSE)
# Use a bandwidth of 0.5 to select galaxy with similar red shifts
# at each window center
h <- 0.5
# Establish a new list called sosies, which stores our
# sosie paris (or triplets)
sosies <- list()
for(c in redshift_centers) {
# Obtain the filtered series
indx <- (1:nrow(dat_small))[abs(redshift-c) <= h/2]
dat_sub <- dat_small[indx,]
# Continue if the subset has more than 1 observation
if (length(indx) > 1) {
# Use DBSCAN to find pairs based on Normalized Magnitude
rslt <- dbscan(cMag_norm[indx, ], minPts = 2, eps = .02)$cluster
# if there is only noise, then skip; otherwise, catalog the pairs with
# their ID
if(length(unique(rslt)) != 1) {
# Obtain total number of groups in clustering result
group.level <- unique(rslt)
for(group in group.level[-1]){
# Obtain id for the galaxies that are classified
# as pairs
groupId <- dat_sub$objid[rslt == group]
sosies <- pairsCatalog(sosies, groupId)
}
}
}
}
# Use rolling window to obtain subset of galaxies with similar redshift
# Use window centers evenly spread out through the range of
redshift_centers <- seq(from = min(dat_small$redshift),
to = max(dat_small$redshift),
length.out=11)
# Use normalized composite magnitude
cMag_bands <- c("c_g", "c_r", "c_i", "c_z")
cMag_norm <- dat_small[, cMag_bands]/dat_small$c_u
#cMag_scaled <- scale(cMag_norm, center=FALSE)
# Use a bandwidth of 0.5 to select galaxy with similar red shifts
# at each window center
h <- 0.5
# Establish a new list called sosies, which stores our
# sosie paris (or triplets)
sosies <- list()
for(c in redshift_centers) {
# Obtain the filtered series
indx <- (1:nrow(dat_small))[abs(redshift-c) <= h/2]
dat_sub <- dat_small[indx,]
# Continue if the subset has more than 1 observation
if (length(indx) > 1) {
# Use DBSCAN to find pairs based on Normalized Magnitude
rslt <- dbscan(cMag_norm[indx, ], minPts = 2, eps = .02)$cluster
# if there is only noise, then skip; otherwise, catalog the pairs with
# their ID
if(length(unique(rslt)) != 1) {
# Obtain total number of groups in clustering result
group.level <- unique(rslt)
for(group in group.level[-1]){
# Obtain id for the galaxies that are classified
# as pairs
groupId <- dat_sub$objid[rslt == group]
sosies <- pairsCatalog(sosies, groupId)
}
}
}
}
# Check the clustering result
rslt1 <- dat_small[dat_small$objid %in% sosies[[2]], ]
matplot(t(rslt1[,c("c_u","c_g","c_r","c_i","c_z")]),type='l')
?hdbscan
table(table(dat_small$objid))
?read.table
# Read in small scaled data
dat_small <- read.csv("../Data/Photo_pairs.csv",
header = TRUE, skip = 1,
numerals="no.loss")
redshift <- dat_small$redshift
pairsCatalog <- function(pairs, vec){
#' pairsCatalog
#'
#' A function that takes in a list pairs and a vec consisited of galaxy IDs; returns
#' a list which has cataloged vec
#'
#' pairs should be a list where each cell contains galaxy IDs. Each cell represents
#' a sosie pair (or triplets).
#'
#' vec is a vector which contains ID that is supposed to be catalogued in the pairs
# Instantiate the updated vector
pairs.updated <- list()
cross_listed.flg <- TRUE
for(pair in pairs){
# If the pair doesn't contain the objects, then just
# append the vector to updated lists
if(sum(pair %in% vec) == 0){
pairs.updated <- append(pairs.updated, list(pair))
}
else{
# If the pair intersects with vec (contain same id), then group
# the pair and vec into a new group and append to the updated
# pairs
cross_listed.flg <- FALSE
pairs.updated <- append(pairs.updated,
list(unique(c(pair, vec))))
}
}
if(cross_listed.flg) {
pairs.updated <- append(pairs.updated, list(vec))
}
return(pairs.updated)
}
pairsCatalog <- function(pairs, vec){
#' pairsCatalog
#'
#' A function that takes in a list pairs and a vec consisited of galaxy IDs; returns
#' a list which has cataloged vec
#'
#' pairs should be a list where each cell contains galaxy IDs. Each cell represents
#' a sosie pair (or triplets).
#'
#' vec is a vector which contains ID that is supposed to be catalogued in the pairs
# Instantiate the updated vector
pairs.updated <- list()
cross_listed.flg <- TRUE
for(pair in pairs){
# If the pair doesn't contain the objects, then just
# append the vector to updated lists
if(sum(pair %in% vec) == 0){
pairs.updated <- append(pairs.updated, list(pair))
}
else{
# If the pair intersects with vec (contain same id), then group
# the pair and vec into a new group and append to the updated
# pairs
cross_listed.flg <- FALSE
pairs.updated <- append(pairs.updated,
list(unique(c(pair, vec))))
}
}
if(cross_listed.flg) {
pairs.updated <- append(pairs.updated, list(vec))
}
return(pairs.updated)
}
# Use rolling window to obtain subset of galaxies with similar redshift
# Use window centers evenly spread out through the range of
redshift_centers <- seq(from = min(dat_small$redshift),
to = max(dat_small$redshift),
length.out=11)
# Use normalized composite magnitude
cMag_bands <- c("c_g", "c_r", "c_i", "c_z")
cMag_norm <- dat_small[, cMag_bands]/dat_small$c_u
#cMag_scaled <- scale(cMag_norm, center=FALSE)
# Use a bandwidth of 0.5 to select galaxy with similar red shifts
# at each window center
h <- 0.5
# Establish a new list called sosies, which stores our
# sosie paris (or triplets)
sosies <- list()
for(c in redshift_centers) {
# Obtain the filtered series
indx <- (1:nrow(dat_small))[abs(redshift-c) <= h/2]
dat_sub <- dat_small[indx,]
# Continue if the subset has more than 1 observation
if (length(indx) > 1) {
# Use DBSCAN to find pairs based on Normalized Magnitude
rslt <- dbscan(cMag_norm[indx, ], minPts = 2, eps = .02)$cluster
# if there is only noise, then skip; otherwise, catalog the pairs with
# their ID
if(length(unique(rslt)) != 1) {
# Obtain total number of groups in clustering result
group.level <- unique(rslt)
for(group in group.level[-1]){
# Obtain id for the galaxies that are classified
# as pairs
groupId <- dat_sub$objid[rslt == group]
sosies <- pairsCatalog(sosies, groupId)
}
}
}
}
# Check the clustering result
rslt1 <- dat_small[dat_small$objid %in% sosies[[2]], ]
matplot(t(rslt1[,c("c_u","c_g","c_r","c_i","c_z")]),type='l')
# Check the clustering result
rslt1 <- dat_small[dat_small$objid %in% sosies[[1]], ]
matplot(t(rslt1[,c("c_u","c_g","c_r","c_i","c_z")]),type='l')
View(sosies)
View(dat_small)
sosies[1]
